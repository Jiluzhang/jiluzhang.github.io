---
title: Squared Loss & Sparse Feature & Perplexity
description: 平方损失  稀疏特征  困惑度
categories:
 - Technical terms
---



- **Squared Loss**

平方损失，线性回归中使用的损失函数，也叫作L2 Loss。

该函数计算**模型对标注样本的预测值和标签真正值之间差的平方**。在平方之后，该损失函数扩大了不良预测的影响，即平方损失比L1 Loss对异常值（outlier）的反应更加强烈。

```
(1) L1 Loss: 绝对值损失函数，目标值附近不太平滑，算法不能很好收敛；
(2) L2 Loss: 欧拉损失函数，在目标附近有更好地曲度，即可导，方便求极值；
(3) Pseudo-Huber Loss: L1损失函数的平滑，当预测值接近目标值时，更接近L2损失函数。
```





- **Sparse Feature**

稀疏特征，**值主要为0或空的特征向量**。

比如，一个向量的值有1个1，一百万个0，则该向量为稀疏向量。

再比如，搜索查询中的单词也是稀疏向量，在一种语言中有很多可以用的单词，但给定查询中只用了其中的一些。





- **Perplexity**

困惑度，**对模型完成任务的程度的一种度量指标**。

例如，假设你的任务是阅读用户在智能手机上输入的单词的头几个字母，并提供可能的完整单词列表。该任务的困惑度P是为了列出包含用户实际想输入单词的列表你需要进行猜测的数量。

困惑度和交叉熵的关系为：P=2<sup>-crossentropy</sup>

```
（1）困惑度的直观理解：平均来说，我们预测下一个词时有多少种选择。
（2）交叉熵：在信息论中，基于相同事件测度的两个概率分布p和q的交叉熵是指，当基于一个“非自然”(相对于“真实”分布p而言)的概率分布q进行编码时，在事件集合中唯一标识一个事件所需要的平均比特数(bit)。
```
